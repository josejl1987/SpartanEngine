/*
Copyright(c) 2015-2026 Panos Karabelas

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and / or sell
copies of the Software, and to permit persons to whom the Software is furnished
to do so, subject to the following conditions :

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
*/

//= INCLUDES ================================
#include "pch.h"
#include "RHI_Texture.h"
#include "RHI_Buffer.h"
#include "RHI_Device.h"
#include "RHI_Shader.h"
#include "RHI_CommandList.h"
#include "RHI_Implementation.h"
#include "ThreadPool.h"
#include "../Rendering/Renderer.h"
#include "../Resource/Import/ImageImporter.h"
#include "../Core/ProgressTracker.h"
#include "../Core/Debugging.h"
#include "../Core/Breadcrumbs.h"
SP_WARNINGS_OFF
#include "compressonator.h"
SP_WARNINGS_ON
//===========================================

//= NAMESPACES =====
using namespace std;
//==================

namespace spartan
{
    namespace compressonator
    {
        CMP_FORMAT to_cmp_format(const RHI_Format format)
        {
            // input
            if (format == RHI_Format::R8G8B8A8_Unorm)
                return CMP_FORMAT::CMP_FORMAT_RGBA_8888;

            // output
            if (format == RHI_Format::BC1_Unorm)
                return CMP_FORMAT::CMP_FORMAT_BC1;

            if (format == RHI_Format::BC3_Unorm)
                return CMP_FORMAT::CMP_FORMAT_BC3;

            if (format == RHI_Format::BC5_Unorm)
                return CMP_FORMAT::CMP_FORMAT_BC5;

            if (format == RHI_Format::BC7_Unorm)
                return CMP_FORMAT::CMP_FORMAT_BC7;

            if (format == RHI_Format::ASTC)
                return CMP_FORMAT::CMP_FORMAT_ASTC;

            SP_ASSERT_MSG(false, "No equivalent format");
            return CMP_FORMAT::CMP_FORMAT_Unknown;
        }

        void compress(RHI_Texture* texture, const uint32_t mip_index, const RHI_Format dest_format)
        {
            // validate mip data exists
            RHI_Texture_Mip* mip = texture->GetMip(0, mip_index);
            if (!mip || mip->bytes.empty())
            {
                SP_LOG_ERROR("Texture '%s' mip %u has no data, skipping compression", texture->GetObjectName().c_str(), mip_index);
                return;
            }

            // calculate dimensions for this mip level (clamp to minimum of 1, same as mip generation)
            uint32_t mip_width  = max(1u, texture->GetWidth() >> mip_index);
            uint32_t mip_height = max(1u, texture->GetHeight() >> mip_index);

            // source texture
            CMP_Texture source_texture = {};
            source_texture.format      = to_cmp_format(texture->GetFormat());
            source_texture.dwSize      = sizeof(CMP_Texture);
            source_texture.dwWidth     = mip_width;
            source_texture.dwHeight    = mip_height;
            source_texture.dwPitch     = source_texture.dwWidth * texture->GetBytesPerPixel();
            source_texture.dwDataSize  = static_cast<uint32_t>(mip->bytes.size());
            source_texture.pData       = reinterpret_cast<uint8_t*>(mip->bytes.data());

            // destination texture
            CMP_Texture destination_texture = {};
            destination_texture.format      = to_cmp_format(dest_format);
            destination_texture.dwSize      = sizeof(CMP_Texture);
            destination_texture.dwWidth     = source_texture.dwWidth;
            destination_texture.dwHeight    = source_texture.dwHeight;
            destination_texture.dwDataSize  = CMP_CalculateBufferSize(&destination_texture);
            vector<std::byte> destination_data(destination_texture.dwDataSize);
            destination_texture.pData       = reinterpret_cast<uint8_t*>(destination_data.data());

            // compress texture
            {
                CMP_CompressOptions options = {};
                options.dwSize              = sizeof(CMP_CompressOptions);
                options.fquality            = 0.05f;                                     // lower quality, faster compression
                options.dwnumThreads        = 1; // single thread to avoid contention with the thread pool
                options.nEncodeWith         = CMP_HPC;                                   // encoder

                SP_ASSERT(CMP_ConvertTexture(&source_texture, &destination_texture, &options, nullptr) == CMP_OK);
            }

            // update texture with compressed data
            texture->GetMip(0, mip_index)->bytes = destination_data;
        }

        void compress(RHI_Texture* texture)
        {
            SP_ASSERT(texture != nullptr);

            RHI_Format target = texture->GetCompressionFormat();
            if (target == RHI_Format::Max)
                target = RHI_Format::BC3_Unorm;

            char marker[128];
            snprintf(marker, sizeof(marker), "texture_compress_cpu: %s", texture->GetObjectName().c_str());
            Breadcrumbs::BeginMarker(marker);

            for (uint32_t mip_index = 0; mip_index < texture->GetMipCount(); mip_index++)
            {
                compress(texture, mip_index, target);
            }

            texture->SetFormat(target);

            Breadcrumbs::EndMarker();
        }
    }

    namespace gpu_compression
    {
        static mutex compress_mutex;

        bool compress(RHI_Texture* texture, RHI_Format target_format)
        {
            SP_ASSERT(texture != nullptr);

            if (Debugging::IsGpuAssistedValidationEnabled() || RHI_Device::IsDeviceLost())
                return false;

            // select shader based on target format
            Renderer_Shader shader_type;
            uint32_t output_element_size = 0; // bytes per compressed block in the output buffer
            uint32_t block_bytes         = 0; // bytes per compressed block on disk
            const char* pso_name         = nullptr;
            switch (target_format)
            {
                case RHI_Format::BC1_Unorm:
                    shader_type         = Renderer_Shader::texture_compress_bc1_c;
                    output_element_size = sizeof(uint32_t) * 2; // uint2
                    block_bytes         = 8;
                    pso_name            = "texture_compress_bc1";
                    break;
                case RHI_Format::BC3_Unorm:
                    shader_type         = Renderer_Shader::texture_compress_bc3_c;
                    output_element_size = sizeof(uint32_t) * 4; // uint4
                    block_bytes         = 16;
                    pso_name            = "texture_compress_bc3";
                    break;
                case RHI_Format::BC5_Unorm:
                    shader_type         = Renderer_Shader::texture_compress_bc5_c;
                    output_element_size = sizeof(uint32_t) * 4; // uint4
                    block_bytes         = 16;
                    pso_name            = "texture_compress_bc5";
                    break;
                default:
                    return false;
            }

            RHI_Shader* shader = Renderer::GetShader(shader_type);
            if (!shader || !shader->IsCompiled())
                return false;

            lock_guard<mutex> lock(compress_mutex);

            char marker[128];
            snprintf(marker, sizeof(marker), "texture_compress_gpu: %s", texture->GetObjectName().c_str());
            Breadcrumbs::BeginMarker(marker);

            const uint32_t width     = texture->GetWidth();
            const uint32_t height    = texture->GetHeight();
            const uint32_t mip_count = texture->GetMipCount();

            uint32_t total_blocks       = 0;
            uint32_t total_input_pixels = 0;
            vector<uint32_t> mip_output_offsets(mip_count);
            vector<uint32_t> mip_input_offsets(mip_count);
            vector<uint32_t> mip_widths(mip_count);
            vector<uint32_t> mip_blocks_x(mip_count);
            vector<uint32_t> mip_block_counts(mip_count);
            for (uint32_t mip = 0; mip < mip_count; mip++)
            {
                uint32_t mip_w = max(1u, width >> mip);
                uint32_t mip_h = max(1u, height >> mip);

                mip_output_offsets[mip] = total_blocks;
                mip_input_offsets[mip]  = total_input_pixels;
                mip_widths[mip]         = mip_w;
                mip_blocks_x[mip]       = max(1u, (mip_w + 3) / 4);
                uint32_t blocks_y       = max(1u, (mip_h + 3) / 4);
                mip_block_counts[mip]   = mip_blocks_x[mip] * blocks_y;
                total_blocks           += mip_block_counts[mip];
                total_input_pixels     += mip_w * mip_h;
            }

            if (total_blocks == 0)
            {
                Breadcrumbs::EndMarker(); // compress_gpu
                return false;
            }

            // the vulkan spec guarantees at least 65535 groups per dispatch axis;
            // bail to cpu if the total work is so large that even a 2D dispatch
            // can't represent it (extremely unlikely: would need >17 billion blocks)
            {
                constexpr uint32_t max_groups_per_axis = 65535;
                uint32_t max_dispatch_groups = (mip_block_counts[0] + 3) / 4;
                if (max_dispatch_groups > static_cast<uint64_t>(max_groups_per_axis) * max_groups_per_axis)
                {
                    Breadcrumbs::EndMarker(); // compress_gpu
                    return false;
                }
            }

            // bail out to cpu compression if we don't have enough vram headroom
            uint64_t min_alignment = RHI_Device::PropertyGetMinStorageBufferOffsetAlignment();
            uint64_t input_stride  = sizeof(uint32_t);
            uint64_t output_stride = output_element_size;
            if (min_alignment > 0)
            {
                if (min_alignment != input_stride)
                    input_stride = (input_stride + min_alignment - 1) & ~(min_alignment - 1);
                if (min_alignment != output_stride)
                    output_stride = (output_stride + min_alignment - 1) & ~(min_alignment - 1);
            }
            uint64_t input_bytes  = static_cast<uint64_t>(total_input_pixels) * input_stride;
            uint64_t output_bytes = static_cast<uint64_t>(total_blocks) * output_stride;
            uint64_t required_mb  = (input_bytes + output_bytes + total_input_pixels * sizeof(uint32_t)) / (1024 * 1024);
            if (RHI_Device::MemoryGetAvailableMb() < required_mb + 256)
            {
                Breadcrumbs::EndMarker(); // compress_gpu
                return false;
            }

            Breadcrumbs::BeginMarker("texture_compress_gpu_buffer_create");

            vector<uint32_t> input_pixels(total_input_pixels);
            for (uint32_t mip = 0; mip < mip_count; mip++)
            {
                RHI_Texture_Mip* mip_data = texture->GetMip(0, mip);
                if (!mip_data || mip_data->bytes.empty())
                {
                    Breadcrumbs::EndMarker(); // buffer_create
                    Breadcrumbs::EndMarker(); // compress_gpu
                    return false;
                }

                uint32_t mip_w       = mip_widths[mip];
                uint32_t mip_h       = max(1u, height >> mip);
                uint32_t pixel_count = mip_w * mip_h;
                memcpy(&input_pixels[mip_input_offsets[mip]], mip_data->bytes.data(), pixel_count * sizeof(uint32_t));
            }

            // input buffer is device-local so the gpu reads from fast vram instead of system ram over pcie
            auto input_buffer = make_shared<RHI_Buffer>(
                RHI_Buffer_Type::Storage,
                static_cast<uint32_t>(sizeof(uint32_t)),
                total_input_pixels,
                nullptr, false,
                "compress_input"
            );

            // output buffer is also device-local so the gpu writes to fast vram
            auto output_buffer = make_shared<RHI_Buffer>(
                RHI_Buffer_Type::Storage,
                static_cast<uint32_t>(output_element_size),
                total_blocks,
                nullptr, false,
                "compress_output"
            );

            if (!input_buffer->GetRhiResource() || !output_buffer->GetRhiResource())
            {
                SP_LOG_ERROR("failed to create buffers for gpu compression");
                Breadcrumbs::EndMarker(); // buffer_create
                Breadcrumbs::EndMarker(); // compress_gpu
                return false;
            }

            // host-visible readback buffer for copying compressed output back to cpu
            auto readback_buffer = make_shared<RHI_Buffer>(
                RHI_Buffer_Type::Storage,
                static_cast<uint32_t>(output_element_size),
                total_blocks,
                nullptr, true,
                "compress_readback"
            );

            if (!readback_buffer->GetRhiResource())
            {
                SP_LOG_ERROR("failed to create readback buffer for gpu compression");
                Breadcrumbs::EndMarker(); // buffer_create
                Breadcrumbs::EndMarker(); // compress_gpu
                return false;
            }

            // host-visible staging buffer for uploading pixel data to the device-local input buffer
            uint64_t staging_size = static_cast<uint64_t>(total_input_pixels) * sizeof(uint32_t);
            auto staging_buffer = make_shared<RHI_Buffer>(
                RHI_Buffer_Type::Storage,
                static_cast<uint32_t>(sizeof(uint32_t)),
                total_input_pixels,
                nullptr, true,
                "compress_staging"
            );
            if (!staging_buffer->GetRhiResource() || !staging_buffer->GetMappedData())
            {
                SP_LOG_ERROR("failed to create staging buffer for gpu compression");
                Breadcrumbs::EndMarker(); // buffer_create
                Breadcrumbs::EndMarker(); // compress_gpu
                return false;
            }
            memcpy(staging_buffer->GetMappedData(), input_pixels.data(), staging_size);

            Breadcrumbs::EndMarker(); // buffer_create

            auto uint_as_float = [](uint32_t val) -> float
            {
                float f;
                memcpy(&f, &val, sizeof(float));
                return f;
            };

            // single command buffer: staging upload -> all mip dispatches -> readback copy
            // all compute reads/writes are device-local vram so the total gpu time is minimal
            Breadcrumbs::BeginMarker("texture_compress_gpu_dispatch");
            {
                RHI_CommandList* cmd_list = RHI_CommandList::ImmediateExecutionBegin(RHI_Queue_Type::Compute);
                if (!cmd_list)
                {
                    Breadcrumbs::EndMarker(); // dispatch
                    Breadcrumbs::EndMarker(); // compress_gpu
                    return false;
                }

                // stage 1: upload pixel data from cpu to device-local input buffer
                {
                    cmd_list->CopyBufferToBuffer(staging_buffer.get(), input_buffer.get(), staging_size);
                    cmd_list->InsertBarrier(input_buffer.get());
                }

                // stage 2: compress all mips (vram to vram, no pcie traffic)
                for (uint32_t mip = 0; mip < mip_count; mip++)
                {
                    uint32_t mip_h = max(1u, height >> mip);

                    RHI_PipelineState pso;
                    pso.name = pso_name;
                    pso.shaders[static_cast<uint32_t>(RHI_Shader_Type::Compute)] = shader;
                    cmd_list->SetPipelineState(pso);

                    cmd_list->SetBuffer(Renderer_BindingsUav::compress_input, input_buffer.get());

                    Renderer_BindingsUav output_binding = (target_format == RHI_Format::BC1_Unorm)
                        ? Renderer_BindingsUav::compress_output_bc1
                        : Renderer_BindingsUav::compress_output;
                    cmd_list->SetBuffer(output_binding, output_buffer.get());

                    Pcb_Pass pass = {};
                    pass.v[0]     = uint_as_float(mip_blocks_x[mip]);
                    pass.v[1]     = uint_as_float(mip_block_counts[mip]);
                    pass.v[2]     = 0.05f;
                    pass.v[3]     = uint_as_float(mip_input_offsets[mip]);
                    pass.v[4]     = uint_as_float(mip_output_offsets[mip]);
                    pass.v[5]     = uint_as_float(mip_widths[mip]);
                    pass.v[6]     = uint_as_float(mip_h);

                    // use 2D dispatch to stay within the 65535-per-axis limit
                    constexpr uint32_t max_groups = 65535;
                    uint32_t total_groups         = (mip_block_counts[mip] + 3) / 4;
                    uint32_t dispatch_x           = min(total_groups, max_groups);
                    uint32_t dispatch_y           = (total_groups + dispatch_x - 1) / dispatch_x;
                    pass.v[7]                     = uint_as_float(dispatch_x);

                    cmd_list->PushConstants(pass);
                    cmd_list->Dispatch(dispatch_x, dispatch_y, 1);

                    cmd_list->InsertBarrier(output_buffer.get());
                }

                // compute->transfer barrier so the readback copy sees completed writes
                cmd_list->InsertBarrier(RHI_Barrier::buffer_sync(output_buffer.get()).from(RHI_Barrier_Scope::Compute).to(RHI_Barrier_Scope::Transfer));
                cmd_list->FlushBarriers();

                // stage 3: copy compressed output from device-local to host-visible readback
                {
                    uint64_t copy_size = static_cast<uint64_t>(total_blocks) * output_element_size;
                    cmd_list->CopyBufferToBuffer(output_buffer.get(), readback_buffer.get(), copy_size);
                }

                RHI_CommandList::ImmediateExecutionEnd(cmd_list);
            }
            Breadcrumbs::EndMarker(); // dispatch

            staging_buffer.reset();

            Breadcrumbs::BeginMarker("texture_compress_gpu_readback");

            void* mapped = readback_buffer->GetMappedData();
            if (!mapped)
            {
                SP_LOG_ERROR("gpu compression readback buffer has no mapped data");
                Breadcrumbs::EndMarker(); // readback
                Breadcrumbs::EndMarker(); // compress_gpu
                return false;
            }

            for (uint32_t mip = 0; mip < mip_count; mip++)
            {
                uint32_t mip_size_bytes = mip_block_counts[mip] * block_bytes;
                uint8_t* src            = reinterpret_cast<uint8_t*>(mapped) + mip_output_offsets[mip] * output_element_size;

                RHI_Texture_Mip* mip_data = texture->GetMip(0, mip);
                if (mip_data)
                {
                    mip_data->bytes.resize(mip_size_bytes);
                    memcpy(mip_data->bytes.data(), src, mip_size_bytes);
                }
            }
            Breadcrumbs::EndMarker(); // readback

            input_buffer->DestroyResourceImmediate();
            output_buffer->DestroyResourceImmediate();
            readback_buffer->DestroyResourceImmediate();

            texture->SetFormat(target_format);

            Breadcrumbs::EndMarker(); // compress_gpu
            return true;
        }
    }

    namespace mips
    {
        void downsample_bilinear(const vector<std::byte>& input, vector<std::byte>& output, uint32_t width, uint32_t height)
        {
            constexpr uint32_t channels = 4; // RGBA32 - engine standard
  
            // calculate new dimensions (halving both width and height)
            uint32_t new_width  = width  >> 1;
            uint32_t new_height = height >> 1;
            
            // ensure minimum size
            if (new_width < 1) new_width = 1;
            if (new_height < 1) new_height = 1;
            
             // perform bilinear downsampling
            for (uint32_t y = 0; y < new_height; y++)
            {
                for (uint32_t x = 0; x < new_width; x++)
                {
                    // calculate base indices for this 2x2 block
                    uint32_t src_idx              = (y * 2 * width + x * 2) * channels;
                    uint32_t src_idx_right        = src_idx + channels;                      // right pixel
                    uint32_t src_idx_bottom       = src_idx + (width * channels);            // bottom pixel
                    uint32_t src_idx_bottom_right = src_idx + (width * channels) + channels; // bottom-right pixel
                    uint32_t dst_idx              = (y * new_width + x) * channels;

                    // process all 4 channels (RGBA)
                    for (uint32_t c = 0; c < channels; c++)
                    {
                        uint32_t sum = to_integer<uint32_t>(input[src_idx + c]);
                        uint32_t count = 1;
            
                        // right pixel
                        if (x * 2 + 1 < width)
                        {
                            sum += to_integer<uint32_t>(input[src_idx_right + c]);
                            count++;
                        }
            
                        // bottom pixel
                        if (y * 2 + 1 < height)
                        {
                            sum += to_integer<uint32_t>(input[src_idx_bottom + c]);
                            count++;
                        }
            
                        // bottom-right pixel
                        if ((x * 2 + 1 < width) && (y * 2 + 1 < height))
                        {
                            sum += to_integer<uint32_t>(input[src_idx_bottom_right + c]);
                            count++;
                        }
            
                        // assign the averaged result to the output
                        output[dst_idx + c] = std::byte(sum / count);
                    }
                }
            }
        }

        uint32_t compute_count(uint32_t width, uint32_t height)
        {
            uint32_t mip_count = 1; // base level counts
            while (width > 1 || height > 1)
            {
                width  = max(1u, width >> 1);
                height = max(1u, height >> 1);
                mip_count++;
            }
            return mip_count;
        }
    }

    namespace binary_format
    {
        struct header
        {
            uint32_t type;
            uint32_t format;
            uint32_t width;
            uint32_t height;
            uint32_t depth;
            uint32_t mip_count;
            uint32_t flags;
            char     name[128];
        };

        bool write_all(ofstream& ofs, const void* data, size_t size)
        {
            ofs.write(reinterpret_cast<const char*>(data), static_cast<streamsize>(size));
            return ofs.good();
        }

        bool read_all(ifstream& ifs, void* data, size_t size)
        {
            ifs.read(reinterpret_cast<char*>(data), static_cast<streamsize>(size));
            return ifs.good();
        }
    }

    RHI_Texture::RHI_Texture() : IResource(ResourceType::Texture)
    {

    }

    RHI_Texture::RHI_Texture(
        const RHI_Texture_Type type,
        const uint32_t width,
        const uint32_t height,
        const uint32_t depth,
        const uint32_t mip_count,
        const RHI_Format format,
        const uint32_t flags,
        const char* name,
        vector<RHI_Texture_Slice> data
    ) : IResource(ResourceType::Texture)
    {
        m_type             = type;
        m_width            = width;
        m_height           = height;
        m_depth            = depth;
        m_mip_count        = mip_count;
        m_format           = format;
        m_flags            = flags;
        m_object_name      = name;
        m_slices           = data;
        m_viewport         = RHI_Viewport(0, 0, static_cast<float>(width), static_cast<float>(height));
        m_channel_count    = rhi_to_format_channel_count(format);
        m_bits_per_channel = rhi_format_to_bits_per_channel(m_format);

        // render targets need gpu resource immediately even without cpu data
        // other textures with empty slices will have data filled later
        bool is_render_target = m_flags & (RHI_Texture_Rtv | RHI_Texture_Uav);
        bool will_fill_data_later = m_slices.empty() && !is_render_target;
        if (!will_fill_data_later)
        {
            PrepareForGpu();
        }

    }

    RHI_Texture::RHI_Texture(const string& file_path) : IResource(ResourceType::Texture)
    {
        LoadFromFile(file_path);
    }

    RHI_Texture::~RHI_Texture()
    {
        RHI_DestroyResource();
    }

    bool RHI_Texture::CanSaveToFile() const
    {
        // requires cpu bytes and compressed format
        bool has_data   = !m_slices.empty() && !m_slices[0].mips.empty() && !m_slices[0].mips[0].bytes.empty();
        bool compressed = IsCompressedFormat(m_format);
        return has_data && compressed;
    }

    void spartan::RHI_Texture::SaveToFile(const string& file_path)
    {
        // require cpu bytes
        if (m_slices.empty() || m_slices[0].mips.empty())
        {
            SP_LOG_WARNING("SaveToFile skipped for %s - no CPU-side data (will re-import from source)", file_path.c_str());
            return;
        }
    
        // require compressed native format
        if (!IsCompressedFormat(m_format))
        {
            SP_LOG_WARNING("SaveToFile skipped for %s - not compressed (will re-import from source)", file_path.c_str());
            return;
        }
    
        binary_format::header hdr = {};
        hdr.type                  = static_cast<uint32_t>(m_type);
        hdr.format                = static_cast<uint32_t>(m_format);
        hdr.width                 = m_width;
        hdr.height                = m_height;
        hdr.depth                 = m_depth;
        hdr.mip_count             = m_mip_count;
        hdr.flags                 = m_flags;
        memset(hdr.name, 0, sizeof(hdr.name));
        {
            string n = m_object_name.empty() ? FileSystem::GetFileNameFromFilePath(file_path) : m_object_name;
            size_t count = min(n.size(), sizeof(hdr.name) - 1);
            copy_n(n.c_str(), count, hdr.name);
            hdr.name[count] = '\0';
        }
    
        ofstream ofs(file_path, ios::binary);
        if (!ofs.is_open())
        {
            SP_LOG_ERROR("SaveToFile failed to open %s", file_path.c_str());
            return;
        }
    
        if (!binary_format::write_all(ofs, &hdr, sizeof(hdr)))
        {
            SP_LOG_ERROR("SaveToFile failed to write header for %s", file_path.c_str());
            return;
        }
    
        // write layout: for each slice, for each mip, write uint64 size then bytes
        for (uint32_t array_index = 0; array_index < m_depth; array_index++)
        {
            const RHI_Texture_Slice& slice = m_slices[array_index];
            if (slice.mips.size() != m_mip_count)
            {
                SP_LOG_ERROR("SaveToFile mip count mismatch on slice %u", array_index);
                return;
            }
    
            for (uint32_t mip_index = 0; mip_index < m_mip_count; mip_index++)
            {
                const auto& mip = slice.mips[mip_index];
                const uint64_t sz = static_cast<uint64_t>(mip.bytes.size());
                if (!binary_format::write_all(ofs, &sz, sizeof(sz)) || !binary_format::write_all(ofs, mip.bytes.data(), mip.bytes.size()))
                {
                    SP_LOG_ERROR("SaveToFile failed while writing slice %u mip %u", array_index, mip_index);
                    return;
                }
            }
        }
    
        ofs.flush();
        if (!ofs.good())
        {
            SP_LOG_ERROR("SaveToFile finalise failed for %s", file_path.c_str());
            return;
        }
    
        // record path for cache
        SetResourceFilePath(file_path);
        SP_LOG_INFO("Saved native compressed texture to %s", file_path.c_str());
    }

    void RHI_Texture::LoadFromFile(const string& file_path)
    {
        ProgressTracker::SetGlobalLoadingState(true);
        ClearData();

        {
            char marker[128];
            snprintf(marker, sizeof(marker), "texture_load: %s", FileSystem::GetFileNameFromFilePath(file_path).c_str());
            Breadcrumbs::BeginMarker(marker);
        }

        // load foreign format
        if (FileSystem::IsSupportedImageFile(file_path))
        {
            m_type            = RHI_Texture_Type::Type2D;
            m_depth           = 1;
            m_flags          |= RHI_Texture_Srv;
            m_object_name     = FileSystem::GetFileNameFromFilePath(file_path);
            m_resource_state  = ResourceState::LoadingFromDrive;

            ImageImporter::Load(file_path, 0, this);
        }
        // load native compressed bytes
        else if (FileSystem::IsEngineTextureFile(file_path))
        {
            ifstream ifs(file_path, ios::binary);
            if (!ifs.is_open())
            {
                SP_LOG_ERROR("Failed to open native texture %s", file_path.c_str());
                Breadcrumbs::EndMarker(); // texture_load
                return;
            }

            binary_format::header hdr{};
            if (!binary_format::read_all(ifs, &hdr, sizeof(hdr)))
            {
                SP_LOG_ERROR("Failed to read header for %s", file_path.c_str());
                Breadcrumbs::EndMarker(); // texture_load
                return;
            }

            // initialise texture fields
            m_type            = static_cast<RHI_Texture_Type>(hdr.type);
            m_format          = static_cast<RHI_Format>(hdr.format);
            m_width           = hdr.width;
            m_height          = hdr.height;
            m_depth           = hdr.depth;
            m_mip_count       = hdr.mip_count;
            m_flags           = hdr.flags | RHI_Texture_Srv;
            m_object_name     = hdr.name[0] ? string(hdr.name) : FileSystem::GetFileNameFromFilePath(file_path);
            m_viewport        = RHI_Viewport(0, 0, static_cast<float>(m_width), static_cast<float>(m_height));
            m_channel_count   = rhi_to_format_channel_count(m_format);
            m_bits_per_channel= rhi_format_to_bits_per_channel(m_format);

            // allocate slices and load mips
            m_slices.resize(m_depth);
            for (uint32_t array_index = 0; array_index < m_depth; array_index++)
            {
                RHI_Texture_Slice& slice = m_slices[array_index];
                slice.mips.resize(m_mip_count);

                for (uint32_t mip_index = 0; mip_index < m_mip_count; mip_index++)
                {
                    uint64_t sz = 0;
                    if (!binary_format::read_all(ifs, &sz, sizeof(sz)) || sz == 0)
                    {
                        SP_LOG_ERROR("Failed to read size for slice %u mip %u in %s", array_index, mip_index, file_path.c_str());
                        Breadcrumbs::EndMarker(); // texture_load
                        return;
                    }

                    RHI_Texture_Mip& mip = slice.mips[mip_index];
                    mip.bytes.resize(static_cast<size_t>(sz));
                    if (!binary_format::read_all(ifs, mip.bytes.data(), static_cast<size_t>(sz)))
                    {
                        SP_LOG_ERROR("Failed to read data for slice %u mip %u in %s", array_index, mip_index, file_path.c_str());
                        Breadcrumbs::EndMarker(); // texture_load
                        return;
                    }
                }
            }

            SP_LOG_INFO("Loaded native texture %s", file_path.c_str());
        }
        else
        {
            SP_LOG_ERROR("Failed to load texture %s: format not supported", file_path.c_str());
        }

        SetResourceFilePath(file_path); // set resource file path so it can be used by the resource cache.
        ComputeMemoryUsage();
        m_resource_state = ResourceState::Max;

        Breadcrumbs::EndMarker(); // texture_load

        // automatically prepare the texture for gpu use
        PrepareForGpu();

        ProgressTracker::SetGlobalLoadingState(false);
    }

    RHI_Texture_Mip* RHI_Texture::GetMip(const uint32_t array_index, const uint32_t mip_index)
    {
        if (array_index >= m_slices.size())
            return nullptr;

        if (mip_index >= m_slices[array_index].mips.size())
            return nullptr;

        return &m_slices[array_index].mips[mip_index];
    }

    RHI_Texture_Slice* RHI_Texture::GetSlice(const uint32_t array_index)
    {
        if (array_index >= m_slices.size())
            return nullptr;

        return &m_slices[array_index];
    }

    void RHI_Texture::AllocateMip(uint32_t slice_index /*= 0*/)
    {
        // ensure slices exist up to the requested index
        while (m_slices.size() <= slice_index)
        { 
            m_slices.emplace_back();
        }

        RHI_Texture_Mip& mip = m_slices[slice_index].mips.emplace_back();
        m_depth              = static_cast<uint32_t>(m_slices.size());
        m_mip_count          = static_cast<uint32_t>(m_slices[slice_index].mips.size());
        uint32_t mip_index   = static_cast<uint32_t>(m_slices[slice_index].mips.size()) - 1;
        uint32_t width       = max(1u, m_width >> mip_index);
        uint32_t height      = max(1u, m_height >> mip_index);
        uint32_t depth       = (GetType() == RHI_Texture_Type::Type3D) ? (m_depth >> mip_index) : 1;
        size_t size_bytes    = CalculateMipSize(width, height, depth, m_format, m_bits_per_channel, m_channel_count);
        mip.bytes.resize(size_bytes);
    }

    void RHI_Texture::ComputeMemoryUsage()
    {
        m_object_size = 0;

        uint32_t array_length = (m_type == RHI_Texture_Type::Type3D) ? 1 : m_depth;
        for (uint32_t array_index = 0; array_index < array_length; array_index++)
        {
            for (uint32_t mip_index = 0; mip_index < m_mip_count; mip_index++)
            {
                const uint32_t mip_width  = max(1u, m_width >> mip_index);
                const uint32_t mip_height = max(1u, m_height >> mip_index);
                const uint32_t mip_depth  = (m_type == RHI_Texture_Type::Type3D) ? max(1u, m_depth >> mip_index) : 1;

                m_object_size += CalculateMipSize(mip_width, mip_height, mip_depth, m_format, m_bits_per_channel, m_channel_count);
            }
        }
    }

    void RHI_Texture::SetLayout(const RHI_Image_Layout new_layout, RHI_CommandList* cmd_list, uint32_t mip_index /*= all_mips*/, uint32_t mip_range /*= 0*/)
    {
        const bool mip_specified = mip_index != rhi_all_mips;
        mip_index                = mip_specified ? mip_index : 0;
        mip_range                = mip_specified ? mip_range : m_mip_count;
    
        if (mip_specified)
        {
            SP_ASSERT(HasPerMipViews());
            SP_ASSERT(mip_range != 0);
            SP_ASSERT(mip_index + mip_range <= m_mip_count);
        }

        cmd_list->InsertBarrier(m_rhi_resource, m_format, mip_index, mip_range, GetArrayLength(), new_layout);
    }

    RHI_Image_Layout RHI_Texture::GetLayout(const uint32_t mip) const
    {
        return m_rhi_resource ? RHI_CommandList::GetImageLayout(m_rhi_resource, mip) : RHI_Image_Layout::Max;
    }

    array<RHI_Image_Layout, rhi_max_mip_count> RHI_Texture::GetLayouts()
    {
        array<RHI_Image_Layout, rhi_max_mip_count> layouts;
        for (uint32_t i = 0; i < rhi_max_mip_count; i++)
        {
            layouts[i] = GetLayout(i);
        }

        return layouts;
    }

    void RHI_Texture::ClearData()
    {
         m_slices.clear();
         m_slices.shrink_to_fit();
    }

    void RHI_Texture::PrepareForGpu()
    {
        // atomically transition from idle to preparing so only one thread can enter
        ResourceState expected = ResourceState::Max;
        if (!m_resource_state.compare_exchange_strong(expected, ResourceState::PreparingForGpu))
            return;

        // skip textures with invalid dimensions (failed to load)
        if (m_width == 0 || m_height == 0)
        {
            SP_LOG_ERROR("Texture '%s' has invalid dimensions (%dx%d), skipping preparation", m_object_name.c_str(), m_width, m_height);
            m_resource_state = ResourceState::Max;
            return;
        }

        {
            char marker[128];
            snprintf(marker, sizeof(marker), "texture_prepare_gpu: %s", m_object_name.c_str());
            Breadcrumbs::BeginMarker(marker);
        }

        bool is_not_compressed   = !IsCompressedFormat();                    // the bistro world loads pre-compressed textures
        bool is_material_texture = IsMaterialTexture() && !m_slices.empty(); // render targets or textures which are written to in compute passes, don't need mip and compression

        if (is_not_compressed && is_material_texture)
        {
            // generate mip chain for all slices
            Breadcrumbs::BeginMarker("texture_mip_generation");
            uint32_t mip_count = mips::compute_count(m_width, m_height);
            for (uint32_t slice_index = 0; slice_index < static_cast<uint32_t>(m_slices.size()); slice_index++)
            {
                for (uint32_t mip_index = 1; mip_index < mip_count; mip_index++)
                {
                    AllocateMip(slice_index);

                    mips::downsample_bilinear(
                        m_slices[slice_index].mips[mip_index - 1].bytes, // larger
                        m_slices[slice_index].mips[mip_index].bytes,     // smaller
                        max(1u, m_width  >> (mip_index - 1)),            // larger width
                        max(1u, m_height >> (mip_index - 1))             // larger height
                    );
                }
            }
            Breadcrumbs::EndMarker(); // mip_generation

            // compress - format is chosen per-texture (bc3 for packed, bc1 for color, bc5 for normal, etc.)
            bool compress       = m_flags & RHI_Texture_Compress;
            bool not_compressed = !IsCompressedFormat();
            if (compress && not_compressed)
            {
                RHI_Format target = m_compression_format != RHI_Format::Max ? m_compression_format : RHI_Format::BC3_Unorm;

                compressonator::compress(this);
            }
        }
        
        // upload to gpu
        if (!RHI_Device::IsDeviceLost())
        {
            Breadcrumbs::BeginMarker("texture_create_resource");
            SP_ASSERT(RHI_CreateResource());
            Breadcrumbs::EndMarker(); // create_resource
        }

        ComputeMemoryUsage();

        if (m_rhi_resource)
        {
            m_resource_state = ResourceState::PreparedForGpu;
        }
        else
        {
            m_resource_state = ResourceState::Max;
        }

        Breadcrumbs::EndMarker(); // prepare_gpu
    }

    bool RHI_Texture::IsCompressedFormat(const RHI_Format format)
    {
        return
            format == RHI_Format::BC1_Unorm ||
            format == RHI_Format::BC3_Unorm ||
            format == RHI_Format::BC5_Unorm ||
            format == RHI_Format::BC7_Unorm ||
            format == RHI_Format::ASTC;
    }

    size_t RHI_Texture::CalculateMipSize(uint32_t width, uint32_t height, uint32_t depth, RHI_Format format, uint32_t bits_per_channel, uint32_t channel_count)
    {
        SP_ASSERT(width  > 0);
        SP_ASSERT(height > 0);
        SP_ASSERT(depth  > 0);

        if (IsCompressedFormat(format))
        {
            uint32_t block_size;
            uint32_t block_width  = 4; // default block width  for BC formats
            uint32_t block_height = 4; // default block height for BC formats
            switch (format)
            {
            case RHI_Format::BC1_Unorm:
                block_size = 8;
                break;
            case RHI_Format::BC3_Unorm:
            case RHI_Format::BC5_Unorm:
            case RHI_Format::BC7_Unorm:
                block_size = 16;
                break;
            case RHI_Format::ASTC: // VK_FORMAT_ASTC_4x4_UNORM_BLOCK
                block_width  = 4;
                block_height = 4;
                block_size  = 16;
                break;
            default:
                SP_ASSERT(false);
                return 0;
            }
            uint32_t num_blocks_wide = (width + block_width - 1) / block_width;
            uint32_t num_blocks_high = (height + block_height - 1) / block_height;
            return static_cast<size_t>(num_blocks_wide) * static_cast<size_t>(num_blocks_high) * static_cast<size_t>(depth) * static_cast<size_t>(block_size);
        }
        else
        {
            SP_ASSERT(channel_count > 0);
            SP_ASSERT(bits_per_channel > 0);
            return static_cast<size_t>(width) * static_cast<size_t>(height) * static_cast<size_t>(depth) * static_cast<size_t>(channel_count) * static_cast<size_t>(bits_per_channel / 8);
        }
    }
}
